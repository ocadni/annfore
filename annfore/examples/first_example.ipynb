{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import annfore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from annfore.net import nn_sir_path_obs\n",
    "from annfore.models import sir_model_N_obs\n",
    "from annfore.utils.graph import find_neighs\n",
    "\n",
    "from annfore.learn.opt import make_opt\n",
    "from annfore.learn.losses import loss_fn_coeff\n",
    "from annfore.learn.train import train_beta, make_training_step_local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "device=\"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# contact array of with entries [time, node_i, node_j, lambda]\n",
    "# ordered by time\n",
    "contacts = np.array([\n",
    "    [0,1,0, 0.5],\n",
    "    [0,0,1, 0.5],\n",
    "    [0,2,0, 0.5],\n",
    "    [0,0,2, 0.5],\n",
    "    [2,3,0, 0.5],\n",
    "    [2,0,3, 0.5],\n",
    "    [3,1,0, 0.5],\n",
    "    [3,0,1, 0.5],\n",
    "])\n",
    "\n",
    "# observations [node, state, time] -- state 0,1,2 for S,I,R\n",
    "# ordered by time\n",
    "\n",
    "obs = [\n",
    "    [1,1,0],\n",
    "    [2,0,0],\n",
    "    [3,1,3],\n",
    "    ]\n",
    "\n",
    "N = int(max(contacts[:, 1]) + 1)\n",
    "t_limit = int(max(contacts[:, 0]) + 1) # t_limit times || +1 obs after contacts\n",
    "mu=0.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SIR model\n",
    "model = sir_model_N_obs.SirModel(contacts, \n",
    "                                mu = mu,\n",
    "                               device = device)\n",
    "model.set_obs(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the autoregressive neurla network\n",
    "dependece_net = find_neighs(contacts,N=N,only_minor=True, next_near_neigh=True)\n",
    "net = nn_sir_path_obs.SIRPathColdObs(dependece_net,\n",
    "                    t_limit+1, # +1 for susceptible\n",
    "                    obs_list=obs,\n",
    "                    hidden_layer_spec=[1,1],\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the optimizer over the parameters of the net\n",
    "optimizer = []\n",
    "lr = 1e-3\n",
    "for i in range(N):\n",
    "    if len(net.params_i[i]):\n",
    "        optimizer.append(make_opt(net.params_i[i], lr=lr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 200 beta: 0.2000, loss: 100.355, std: 18.045, ener: 109.13, max_grad = 0.0, count_zero_pw = 141.00, num_I = 1.620, num_R = 0.1000 (T_obs=0) -- took      7 ms: sample: 1, log_prob: 0, trans_sample: 0, energy: 1, loss: 0, optim_step: 3, stats: 0 -- source: {   1:1.000,   3:0.440,   0:0.180,   2:0.000}    - remain time:  5 s, 646 msdict_keys(['step', 'beta', 'energy', 'std_energy', 'loss', 'loss_std', 'S', 'I', 'R', 't_obs', 'num_source', 'sources', 'max_grad', 'num_zero_pw', 'N', 'T', 'p_source', 'p_sus', 'p_obs', 'p_w', 'mu', 'times'])\n",
      " 400 beta: 0.4000, loss: 72.050, std: 10.798, ener: 76.83, max_grad = 0.0, count_zero_pw = 22.00, num_I = 1.370, num_R = 0.0100 (T_obs=0) -- took      7 ms: sample: 1, log_prob: 0, trans_sample: 0, energy: 1, loss: 0, optim_step: 3, stats: 0 -- source: {   1:1.000,   3:0.200,   0:0.170,   2:0.000}    - remain time:  4 s, 232 msdict_keys(['step', 'beta', 'energy', 'std_energy', 'loss', 'loss_std', 'S', 'I', 'R', 't_obs', 'num_source', 'sources', 'max_grad', 'num_zero_pw', 'N', 'T', 'p_source', 'p_sus', 'p_obs', 'p_w', 'mu', 'times'])\n",
      " 600 beta: 0.6000, loss: 64.515, std: 3.568, ener: 67.47, max_grad = 0.0, count_zero_pw = 2.00, num_I = 1.070, num_R = 0.0000 (T_obs=0) -- took      7 ms: sample: 1, log_prob: 0, trans_sample: 0, energy: 1, loss: 0, optim_step: 3, stats: 0 -- source: {   1:1.000,   0:0.040,   3:0.030,   2:0.000}    - remain time:  2 s, 793 msdict_keys(['step', 'beta', 'energy', 'std_energy', 'loss', 'loss_std', 'S', 'I', 'R', 't_obs', 'num_source', 'sources', 'max_grad', 'num_zero_pw', 'N', 'T', 'p_source', 'p_sus', 'p_obs', 'p_w', 'mu', 'times'])\n",
      " 800 beta: 0.8000, loss: 63.706, std: 1.930, ener: 66.11, max_grad = 0.0, count_zero_pw = 1.00, num_I = 1.010, num_R = 0.0000 (T_obs=0) -- took      7 ms: sample: 1, log_prob: 0, trans_sample: 0, energy: 2, loss: 0, optim_step: 3, stats: 0 -- source: {   1:1.000,   0:0.010,   2:0.000,   3:0.000}    - remain time:  1 s, 393 msdict_keys(['step', 'beta', 'energy', 'std_energy', 'loss', 'loss_std', 'S', 'I', 'R', 't_obs', 'num_source', 'sources', 'max_grad', 'num_zero_pw', 'N', 'T', 'p_source', 'p_sus', 'p_obs', 'p_w', 'mu', 'times'])\n",
      " 999 beta: 0.9990, loss: 64.039, std: 3.999, ener: 66.16, max_grad = 0.0, count_zero_pw = 3.00, num_I = 1.010, num_R = 0.0000 (T_obs=0) -- took      7 ms: sample: 1, log_prob: 0, trans_sample: 0, energy: 1, loss: 0, optim_step: 3, stats: 0 -- source: {   1:1.000,   0:0.010,   2:0.000,   3:0.000}    - remain time:   0 msdict_keys(['step', 'beta', 'energy', 'std_energy', 'loss', 'loss_std', 'S', 'I', 'R', 't_obs', 'num_source', 'sources', 'max_grad', 'num_zero_pw', 'N', 'T', 'p_source', 'p_sus', 'p_obs', 'p_w', 'mu', 'times'])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t_obs = 0\n",
    "betas = np.arange(0,1, 1e-3)\n",
    "num_samples = 100\n",
    "results = train_beta(net, optimizer,\n",
    "                        model, \"out.txt\",\n",
    "                        loss_fn_coeff, t_obs,\n",
    "                        num_samples=num_samples,\n",
    "                        train_step = make_training_step_local,\n",
    "                        betas=betas, save_every=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = net.marginals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0071, 1.0000, 0.0000, 0.0056])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M[:, 0,1] # marginal probability to be infected of nodes (0,1,2,3) at time t = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "63289e09a2577d8cfdd70b9f838bc057d3af83fa8d314fd25a511c3cad8291bb"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('annfore': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
